<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Compiling stack-based assembly to C • Wim Vanderbauwhede</title>
    <meta name="description" content="What does it take to bring functional programming to a stack-based assembly language?">
    <meta name="keywords" content="compilers">
    

    <link rel="canonical" href="https://wimvanderbauwhede.github.io/articles/uxntal-to-C/">

    <link href="https://wimvanderbauwhede.github.io/atom.xml" type="application/atom+xml" rel="alternate" title="Wim Vanderbauwhede Atom Feed">
    <link href="https://wimvanderbauwhede.github.io/sitemap.xml" type="application/xml" rel="sitemap" title="Sitemap">

    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="cleartype" content="on">
    <meta name="p:domain_verify" content="e31ad34d4267c0ac4d997da5cb5ea898"/>
    <meta http-equiv="X-Clacks-Overhead" content="GNU Natalie Nguyen" />
    <!-- <style>
    .sliding-menu-content {
      top: 0;
      right: 0;
      text-align: center;
      visibility: hidden;
      height: 100%;
      width: 100%;
      -webkit-transform: translateX(100%);
      -moz-transform: translateX(100%);
      -ms-transform: translateX(100%);
      -o-transform: translateX(100%);
      transform: translateX(100%);
    }
    </style> -->

    <link rel="stylesheet" href="https://wimvanderbauwhede.github.io/css/main.css">
    <!-- <link rel="stylesheet" href="https://wimvanderbauwhede.github.io/css/bjqs.css"> -->
    <!-- <link rel="stylesheet" href="https://wimvanderbauwhede.github.io/tipuesearch/tipuesearch.css"> -->
    <!-- HTML5 Shiv and Media Query Support for IE -->
    <!--[if lt IE 9]>
      <script src="https://wimvanderbauwhede.github.io/js/vendor/html5shiv.min.js"></script>
      <script src="https://wimvanderbauwhede.github.io/js/vendor/respond.min.js"></script>
    <![endif]-->
    <!-- Include the jQuery library (local or CDN) -->
    <!-- <script src="https://wimvanderbauwhede.github.io/js/plugins/jquery-1.7.1.min.js"></script> -->

    <!-- Include the plugin *after* the jQuery library -->
    <!-- <script src="https://wimvanderbauwhede.github.io/js/plugins/bjqs-1.3.min.js"></script> -->
        
  </head>

  <body>
    <header id="masthead">
  <div class="inner-wrap">
<a href="https://wimvanderbauwhede.github.io" class="site-title">&nbsp;</a>
    <nav role="navigation" class="menu top-menu">
        <ul class="menu-item">
	<li class="home"><a href="/">Wim Vanderbauwhede</a></li>
	

</ul>

    </nav>
<!-- <form style="float: right;" action="https://wimvanderbauwhede.github.io/search.html" ><input type="text" name="q" id="tipue_search_input" autocomplete="off" required></form> -->
  </div><!-- /.inner-wrap -->
</header><!-- /.masthead -->

    <!-- <nav role="navigation" class="js-menu sliding-menu-content">
	<ul class="menu-item">
		
	</ul>
</nav>
<button type="button" class="js-menu-trigger sliding-menu-button menulines-button x2" role="button" aria-label="Toggle Navigation">
	<span class="menulines"></span>
</button>

<div class="js-menu-screen menu-screen"></div>
 -->

    <div id="page-wrapper">

      <div id="main" role="main">
	<article class="wrap" itemscope itemtype="http://schema.org/Article">
		
		<div class="page-feature">
			<div class="page-image">
				<img src="https://wimvanderbauwhede.github.io/images/uxntal-to-C_1600x600.avif" class="page-feature-image" alt="Compiling stack-based assembly to C" itemprop="image">
				
			</div><!-- /.page-image -->
		</div><!-- /.page-feature -->
		
		<nav class="breadcrumbs">
  <a href="https://wimvanderbauwhede.github.io">Home</a> <span class="divider">/</span> <a href="https://wimvanderbauwhede.github.io/articles/">Articles</a> <span class="divider">/</span>
</nav><!-- /.breadcrumbs -->
		<div class="page-title">
			<h1>Compiling stack-based assembly to C</h1>
		</div>
		<div class="inner-wrap">
			<nav class="toc"></nav><!-- /.toc -->
			<div id="content" class="page-content" itemprop="articleBody">
				<p>I wrote a proof-of-concept compiler from <a href="https://wiki.xxiivv.com/site/uxntal.html">Uxntal</a> to <code class="language-plaintext highlighter-rouge">C</code>. The generated code is linked with a slightly modified version of the <a href="https://git.sr.ht/~rabbits/uxn">Uxn VM/Varvara code</a> to provide stand-alone applications.</p>

<h2 id="uxntal-and-uxn">Uxntal and Uxn</h2>

<p><a href="https://wiki.xxiivv.com/site/uxntal.html"><code class="language-plaintext highlighter-rouge">Uxntal</code></a> is the programming language for the <a href="https://wiki.xxiivv.com/site/uxn.html"><code class="language-plaintext highlighter-rouge">Uxn</code></a> virtual machine which forms the heart of the <a href="https://wiki.xxiivv.com/site/varvara.html"><code class="language-plaintext highlighter-rouge">Varvara</code></a> clean-slate computing stack. As Uxn is a stack machine, Uxntal is a stack language, similar to e.g. <a href="https://forth-standard.org/">Forth</a> or <a href="https://dev.to/palm86/church-encoding-in-the-concatenative-language-joy-3nd8">Joy</a> in that it uses reverse Polish notation (postfix). It is an assembly language with opcodes for 8-bit and 16-bit operations on the stack and memory. To get the most out of this article, it is best if you have basic knowledge of Uxntal, either from the above resources or for example <a href="https://compudanzas.net/uxn_tutorial.html">the great tutorial at Compudanzas</a>.</p>

<h2 id="an-uxntal-to-c-compiler">An Uxntal-to-C compiler</h2>

<p>What I call an Uxntal-to-C compiler is a program that converts an Uxntal program into a C program that, when compiled with a C compiler and executed, has the same functionality as the Uxntal program has when assembled and run on the Uxn emulator.</p>

<p>Why compile Uxntal to C? Mainly for fun, and out of curiosity. I was curious about the challenges involved and the limitations. Compiling Uxntal programs does result in speed-ups for compute-intensive applications. However, the fact that Uxn is computationally not very efficient is to my mind a bit of a red herring. As the main purpose of Uxn is to create interactive applications, the behaviour of these is dominated by the I/O activity, including the display and audio which are managed by SDL. The effect of the Uxntal code being compiled or interpreted will therefore be small for typical Uxn target, because either the program run time will be dominated by I/O waits or the computations will take place in the SDL layer. And that was another reason behind this experiment: it provides evidence. I verified my assumptions on a number of examples (see below), and the total power saving of the compiled version is negligible.</p>

<p>I initially considered <a href="https://llvm.org">LLVM</a> and <a href="https://webassembly.github.io">WASM</a> as targets. WASM seems attractive at first because it is purportedly stack based, but it turns out that loops are not stack based, nor is function argument passing. Both WASM and LLVM are typed assembly languages and assume that code and data are in separate memory spaces and that code is read-only, so they offer no additional benefit as a compilation target for Uxntal over C.</p>

<h2 id="limitations">Limitations</h2>

<p>There are two aspects of Uxntal that can’t be supported in an ahead-of-time C compiler with static code analysis.</p>

<h3 id="jumps-to-computed-addresses">Jumps to computed addresses</h3>

<p>The first is jumps to computed addresses, because that is a concept that is not supported in C (nor in LLVM or WASM). A jump to a constant relative address can be resolved at compile time and supported, but run-time computed jumps have no equivalent. Fortunately, in practice Uxntal’s linter discourages this for jumps longer than one instruction, and the allowed case of a run-time computed binary value is supported.</p>

<h3 id="self-modifiable-code">Self-modifiable code</h3>

<p>The second is self-modifiable code. In C, LLVM and WASM, code and data are separated and a program can’t modify its on source. Fortunately, in practice the use of self-modification in Uxntal is limited to storing of local variables through code such as</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LIT &amp;x $1 
</code></pre></div></div>

<p>and evaluation of instructions from the stack using code such as</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>LIT MUL
... 
#00 STR $1
</code></pre></div></div>

<p>Run-time evaluation through self-modification of the instructions is only supported for a specific case:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#06 #07 LIT ADD 
...
#00 STR BRK 
</code></pre></div></div>

<p>In principle, any store of a byte in the code memory results in self-modification, but the above is the most common pattern used to evaluate a byte on the stack as an instruction.</p>

<p>Also fundamentally, the compiler expects human-readable Uxntal code, in particular it relies on the mnemonics to identify instructions. So while this is valid Uxntal code, it will not work:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>80 06 80 07 1a
</code></pre></div></div>

<p>It is in general impossible for a compiler to distinguish between opcodes and data because of Uxntal’s dynamic nature. In fact, a value can be used as both depending on a run-time condition. So the compiler needs the meta-information provided by the mnemonic notation.</p>

<h2 id="design">Design</h2>

<p>The overall approach is to use the runtime data structures used in the Uxn emulator, i.e. arrays that represent the ram, stacks and devices. Rather than reading bytes from the rom file and evaluating them using a case statement, we generate C code with subroutines corresponding to the instructions. The control flow is purely based on subroutine calls.</p>

<p>The design is quite simple. There is a Token sum type for all token variants and some record types for code blocks and the full program. All of these are in <a href="https://codeberg.org/wimvanderbauwhede/nito/lib/UxntalTypes.rakumod"><code class="language-plaintext highlighter-rouge">UxntalTypes</code></a>. Definitions of the Uxntal operations are in <a href="https://codeberg.org/wimvanderbauwhede/nito/lib/UxntalDefs.rakumod"><code class="language-plaintext highlighter-rouge">UxntalDefs</code></a>.</p>

<p>Because of Uxntal’s very regular structure, the <a href="https://codeberg.org/wimvanderbauwhede/nito/lib/UxntalTokeniser.rakumod">tokeniser</a> is trivial (split on whitespace and newlines); the <a href="https://codeberg.org/wimvanderbauwhede/nito/lib/UxntalParser.rakumod">parser</a> is using regular expressions and is also straightforward. Because Uxntal programs are simply sequences of instructions, labels and data of one or two bytes, the parser does need only limited context. We parse the code into a data type that reflects the different types of tokens as described on the <a href="https://wiki.xxiivv.com/site/uxntal.html">Uxntal page of the XXIIVV wiki</a>:</p>

<table border="1">
	<tr><th colspan="4">Padding</th><th colspan="4">Literals</th></tr>
	<tr><td><code>|</code></td><td>absolute</td><td><code>$</code></td><td>relative</td><td><code>#</code></td><td colspan="3">literal hex</td></tr>
	<tr><th colspan="4">Labels</th><th colspan="4">Ascii</th></tr>
	<tr><td><code>@</code></td><td>parent</td><td><code>&amp;</code></td><td>child</td><td><code>&quot;</code></td><td>raw word</td><td><code>&#39;</code></td><td>raw char</td></tr>
	<tr><th colspan="4">Addressing</th><th colspan="4">Pre-processor</th></tr>
	<tr><td><code>,</code></td><td>literal relative</td><td>.</td><td>literal zero-page</td><td><code>%</code></td><td>macro-define</td><td><code>~</code></td><td>include</td></tr>
	<tr><td><code>:</code></td><td>raw absolute</td><td><code>;</code></td><td>literal absolute</td></tr>
</table>

<p>Then we perform two transformation passes:</p>

<ul>
  <li>
    <p>Replace all relative addressing by absolute addressing.</p>

    <p>So after this step, only <code class="language-plaintext highlighter-rouge">@</code>, <code class="language-plaintext highlighter-rouge">.</code> and <code class="language-plaintext highlighter-rouge">;</code> remain.</p>
  </li>
  <li>
    <p>Split the code into blocks and identify them as subroutines or data.</p>

    <p>This is only slightly more complex because we need to add an explicit jump to the next block for blocks that do not end in a jump. Blocks that do not contain operations are considered data, all other blocks are subroutines.</p>
  </li>
</ul>

<p>This transformation allows us to create equivalent C subroutines an  store the data in RAM. There are a few special cases, see the <a href="https://codeberg.org/wimvanderbauwhede/nito/lib/UxntalParser.rakumod"><code class="language-plaintext highlighter-rouge">UxntalParser</code></a> code for details.</p>

<p>After this step we <a href="https://codeberg.org/wimvanderbauwhede/nito/lib/UxntalAnalyser.rakumod">analyse</a> the code to determine which labels refer to subroutines and which to data.</p>

<p>The main advantage of this approach is that it simplifies control flow handling: there is no need for <code class="language-plaintext highlighter-rouge">goto</code> statements or labels because Uxntal’s label-based loops have been turned into recursive subroutines. So all we need to do is generate the code for those subroutines and the code to call them.</p>

<p>The actual <a href="https://codeberg.org/wimvanderbauwhede/nito/lib/UxntalStackBasedCEmitter.rakumod">emitter</a> is straightforward because it relies on <a href="https://codeberg.org/wimvanderbauwhede/nito/uxn-runtime-libs/">a runtime library</a> which contains a subroutine for every Uxntal instruction.</p>

<p>In practice there are a few additional complications, specifically to handle the limited use of self-modification, and to handle conditional jumps. Also, the memory allocations and subroutine declarations need to be collected and grouped at the start of the source code, so there is quite a bit of state to be maintained.</p>

<p>Each instruction subroutine takes the required arguments from the stack and pushes its result on the stack, if any. Consequently, all subroutines have a signature <code class="language-plaintext highlighter-rouge">void f(void)</code>. This means all function pointers are of the same type. Because function pointers in C are machine size, we can’t put them directly on the Uxn stack. Instead, we store them in a separate array and put the index into that array on the stack.</p>

<p>With this approach, we can handle most of the dynamic nature of Uxntal.</p>

<h2 id="optimisations">Optimisations</h2>

<h3 id="inlining-operations">Inlining operations</h3>

<p>The generated C code at this stage has a very large number of subroutine calls, and disappointingly the C compiler (gcc) does not inline most of them. So we do this ourselves in a <a href="https://codeberg.org/wimvanderbauwhede/nito/lib/UxntalStackBasedCOpsEmitter.rakumod">first optimisation pass</a>. This is easy (if cumbersome) because the subroutines don’t take or return arguments and are guaranteed non-recursive, so we can simply replace the call with the definition.</p>

<h3 id="stack-to-register">Stack to register</h3>

<p>A <a href="https://codeberg.org/wimvanderbauwhede/nito/lib/UxntalStackBasedCOpsEmitter.rakumod">second optimisation</a> is more complicated but has also a much bigger effect on performance: we replace as much as possible stack operations with register operations. This is a little bit more complicated than at first sight appears. I might write a separate post about the algorithm.</p>

<h3 id="further-optimisations">Further optimisations</h3>

<p>There are a number of further optimisations that could be considered, but all of them are more complex and would not result in a dramatic additional performance improvement. Some of them I have implemented but they are not enabled:</p>

<ul>
  <li>
    <p><a href="https://codeberg.org/wimvanderbauwhede/nito/lib/UxntalInliner.rakumod">Inline subroutines</a>. This is only partially implemented. It is rather tricky because recursive subroutines can’t be inlined, so we need an analysis to detect recursion. For simple, in-routine recursion that is easy, but recursion can occur through a chain of tail calls, so we need to identify tail calls and follow those through.</p>
  </li>
  <li>
    <p>Use <code class="language-plaintext highlighter-rouge">goto</code> instead of function call. This is a simple optimisation which does not require a separate pass so it’s done directly in the <a href="https://codeberg.org/wimvanderbauwhede/nito/lib/UxntalStackBasedCEmitter.rakumod">emitter</a>.</p>
  </li>
</ul>

<p>Both of these optimisations make little or no difference for most applications I tested so I don’t enable them. Some other optimisations I have not finished implementing:</p>

<ul>
  <li>
    <p>Stack to register for subroutine calls. This is quite complicated, mostly because of recursion, but also because it is (in general) not possible to infer the type of a function called via a function pointers.</p>
  </li>
  <li>
    <p>Stack to register for conditional blocks. This is the case where a condition is created through a computed jump, a typical example would be</p>

    <p>… EQU JMP [ INC2 ] …</p>
  </li>
</ul>

<p>So if <code class="language-plaintext highlighter-rouge">EQU</code> returns 0, <code class="language-plaintext highlighter-rouge">ADD2</code> will be executed, else it will be jumped over. The instruction has to be idempotent, and I think most commonly this is used with <code class="language-plaintext highlighter-rouge">JMP2r</code>. The effect on performance will generally be minimal.</p>

<h2 id="performance">Performance</h2>

<h3 id="code-used-for-testing">Code used for testing</h3>

<p>I did some limited performance evaluation using five command-line programs: three versions of <code class="language-plaintext highlighter-rouge">fib*</code>, <code class="language-plaintext highlighter-rouge">primes</code>, and <code class="language-plaintext highlighter-rouge">stencil</code>. With <code class="language-plaintext highlighter-rouge">-O=2</code> (inlined ops and stack-to-reg), the compiled version is up to 12x faster than the original version. With the additional optimisations this might increase a bit, maybe to     15x, but not more.</p>

<p>The three version of the Fibonacci calculation are a modified version of <a href="https://git.sr.ht/~rabbits/uxn/tree/main/item/projects/examples/exercises/fib.tal"><code class="language-plaintext highlighter-rouge">uxn/projects/examples/exercises/fib.tal</code></a> and the two versions used in <a href="https://applied-langua.ge/posts/i-dont-want-to-go-to-chel-c.html">an article</a> that criticised Uxn for being inefficient.</p>

<p>The original <a href="https://git.sr.ht/~rabbits/uxn/tree/main/item/projects/examples/exercises/fib.tal"><code class="language-plaintext highlighter-rouge">fib.tal</code></a> is very terse (ignoring the <code class="language-plaintext highlighter-rouge">print</code> function):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|0100 ( -&gt; ) @reset

    #0000 INC2k ADD2k
    &amp;loop
        ( print ) DUP2 ,print JSR
        ( linebreak ) #0a18 DEO
        ADD2k LTH2k ,&amp;loop JCN
    ( halt ) #010f DEO

BRK
</code></pre></div></div>

<p>I <a href="https://codeberg.org/wimvanderbauwhede/nito/src/branch/main/demos/fib.tal">modified it</a> by writing a loop around it to repeat the calculations 2^16 times:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#ffff #0000 &amp;iterate
...
INC2 GTH2k ,&amp;iterate JCN
</code></pre></div></div>

<p>What I call <code class="language-plaintext highlighter-rouge">fib2.tal</code> is taken from the article:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|0100

#0020 ;fib JSR2
#01 #0f DEO BRK

@fib ( N -- fib[N] )
    DUP2 #0001 GTH2 ,&amp;inductive-case; JCN JMP2r
    &amp;inductive-case;
    DUP2 #0001 SUB2 ;fib JSR2 ( stack now N fib[N-1] )
    SWP2 #0002 SUB2 ;fib JSR2 ( stack now fib[N-1] fib[N-2] )
    ADD2 JMP2r
</code></pre></div></div>

<p>And <code class="language-plaintext highlighter-rouge">fib32.tal</code> is a 32-bit version of this code, also from that article:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|0100

#0020 ;fib JSR2
#01 #0f DEO BRK

@fib ( N -- fib[N] )
( not[n &lt; 2] equivalent to n &gt; 1 )
    DUP2 #0001 GTH2 ,&amp;inductive-case; JCN #0000 SWP JMP2r
    &amp;inductive-case;
    DUP2 #0001 SUB2 ;fib JSR2 ( stack now N fib[N-1] )
    ROT2 #0002 SUB2 ;fib JSR2 ( stack now fib[N-1] fib[N-2] )
    ;add32 JSR2 JMP2r
</code></pre></div></div>

<p>This uses the <a href="http://plastic-idolatry.com/erik/nxu/math32.tal">32-bit math library</a>.</p>

<p>I also tested <a href="https://git.sr.ht/~rabbits/uxn/tree/main/item/projects/examples/exercises/primes.tal"><code class="language-plaintext highlighter-rouge">uxn/projects/examples/exercises/primes.tal</code></a>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|0100 ( -&gt; ) @reset

    #0000 INC2k
    &amp;loop
        DUP2 ,is-prime JSR #00 EQU ,&amp;skip JCN
            DUP2 DUP2 ;mem STA2
            ,print/short JSR
            ( space ) #2018 DEO
            &amp;skip
        INC2 NEQ2k ,&amp;loop JCN
    POP2 POP2
    ;mem LDA2 ,print/short JSR
    ( halt ) #010f DEO

BRK

@is-prime	
    DUP2
    #0001 EQU2 ,&amp;fail JCN
    STH2k
    #01 SFT2 #0002
    &amp;loop
        STH2kr OVR2 ( mod2 ) [ DIV2k MUL2 SUB2 ] ORA ,&amp;continue JCN
            POP2 POP2 POP2r #00 JMP2r
            &amp;continue
        INC2  GTH2k ,&amp;loop JCN
    POP2 POP2 POP2r #01
JMP2r
    &amp;fail POP2 #00 JMP2r
</code></pre></div></div>

<p>Finally, I wrote <a href="https://codeberg.org/wimvanderbauwhede/nito/src/branch/main/demos/stencil.tal"><code class="language-plaintext highlighter-rouge">stencil.tal</code></a>, which is a 3-D 6-point stencil code, so the value of each point in a 3-D space is calculated based on the values of its six neighbours (i+1,i-1),(j+1,j-1),(k+1,k-1). This is a very common pattern in scientific computing and a good number crunching test. The code is a bit long to list here. It is a quadruple-nested loop: a time loop containing loops over the x, y and z directions of the 3-D space. At each point, the calculation is simply the weighted average of the current value and the sum of the six neighbours:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>.idx LDZ2 #0001 ADD2 LDA2 ( p(x-1,y,z) )
.idx LDZ2 #0001 SUB2 LDA2 ( p(x+1,y,z) )
ADD2
.idx LDZ2 #0010 ADD2 LDA2 ( p(x,y-1,z) )
.idx LDZ2 #0010 SUB2 LDA2 ( p(x,y+1,z) )
ADD2
ADD2
.idx LDZ2 #0100 ADD2 LDA2 ( p(x,y,z-1) )
.idx LDZ2 #0100 SUB2 LDA2 ( p(x,y,z+1) )
ADD2 
ADD2
#0003 MUL2 

.idx LDZ2 LDA2 ( p(x,y,z) ) 
ADD2
#0004 DIV2
</code></pre></div></div>

<p>The time loop repeats this calculation 2^16 times.</p>

<h3 id="performance-results">Performance results</h3>

<p>I compiled these example with as optimisations inlining of operations and stack-to-register transformation. I used <code class="language-plaintext highlighter-rouge">time</code> to obtain the timings.</p>

<table>
	<tr><th>Code</th><th>Emulated (s)</th><th>Compiled (s)</th><th>Speed-up</th></tr>
	<tr><td><code>fib.tal</code></td><td>1.57</td><td>0.96</td><td>1.6x</td></tr>
	<tr><td><code>fib2.tal</code></td><td>0.471</td><td>0.047</td><td>10x</td></tr>
	<tr><td><code>fib32.tal</code></td><td>1.86</td><td>0.151</td><td>12.3x</td></tr>
	<tr><td><code>primes.tal</code></td><td>6.9</td><td>0.93</td><td>7.4x</td></tr>
	<tr><td><code>stencil.tal</code></td><td>96.9</td><td>7.8</td><td>12.4x</td></tr>
</table>

<p>For the examples with low speed-ups, the reason is that a lot of the time spend is I/O activity, which takes the same amount of time for the emulated and compiled versions:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ time uxncli fib.rom &gt;/dev/null
real	0m1.568s
user	0m0.924s
sys	0m0.644s

$ time uxncliprog &gt;/dev/null
real	0m0.964s
user	0m0.384s
sys	0m0.580s
</code></pre></div></div>

<p>Even if we print to <code class="language-plaintext highlighter-rouge">/dev/null</code>, that still takes considerable I/O time.</p>

<p>For the tests without I/O (fib2, fib32, stencil), the speed-up is between 10x and 12.4x. I think with the additional optimisations, it might increase to maybe 15x but not more than that.</p>

<h2 id="power-consumption">Power consumption</h2>

<p>Finally, I had a look at the power consumption of a typical GUI-based Uxn app. I used powertop with the <a href="https://git.sr.ht/~rabbits/uxn/tree/main/item/projects/examples/demos/bunnymark.tal"><code class="language-plaintext highlighter-rouge">bunnymark</code></a> benchmark, running 10,000 rabbits. I used <code class="language-plaintext highlighter-rouge">htop</code> for the CPU utilsation.</p>

<p>My laptop is nearly three years old, it is a <a href="https://www.pcspecialist.co.uk">PCSpecialist</a> Fusion IV, which is really a <a href="http://www.hk.tongfangpc.com/">TongFang</a> PF4MN2F. The CPU is an Intel Core i7-10510U 1.80GHz and it has 16GB DDR4 memory.</p>

<h3 id="baseline">Baseline</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>System baseline power is estimated at 766 mW

Power est.    Usage     Device name
564 mW      3.1%        DRAM
157 mW      3.1%        CPU core
44.9 mW      3.1%        CPU misc
</code></pre></div></div>

<h3 id="emulated">Emulated</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>15% CPU

System baseline power is estimated at 7.98 W

Power est.    Usage     Device name
5.03 W     57.7%        CPU core
1.43 W     57.7%        CPU misc
1.02 W     57.7%        DRAM
</code></pre></div></div>

<h3 id="compiled">Compiled</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>9% CPU

System baseline power is estimated at 8.17 W

Power est.    Usage     Device name
5.09 W     55.4%        CPU core
1.59 W     55.4%        CPU misc
978 mW     55.4%        DRAM    
</code></pre></div></div>

<p>What we see is that most of the power is drawn by the CPU and that there is effectively no difference between the emulated and compiled versions. I measured this a few times and the error margin is about 0.5 W so within that margin the results are identical. I also measured the power consumption for emulated and compiled versions of other applications in the <a href="https://git.sr.ht/~rabbits/uxn/tree/main/item/projects/examples/demos"><code class="language-plaintext highlighter-rouge">demos</code></a> folder. They all consume considerably less power than bunnymark but there was no significant difference between emulated and compiled versions.</p>

<h2 id="conclusion">Conclusion</h2>

<p>The main takeaway of this experiment of compiling Uxntal to C is that it provides evidence that there is no need to do this for most Uxn applications: it will have no significant effect on performance or power consumption.</p>

<p>On the other hand, if you have to or want to you now can compile Uxntal to C and it can give speed-ups of the order of 10x for compute-heavy applications.</p>

<h2 id="code">Code</h2>

<p>The compiler code and demos can be found <a href="https://codeberg.org/wimvanderbauwhede/nito">in my <code class="language-plaintext highlighter-rouge">nito</code> repo on Codeberg</a>. The README has the instructions and a list of the code on which I tested the compiler.</p>

<p><br /></p>

<p><em>The banner picture shows a row of bronze prayer wheels in a temple in Kyoto at night.</em></p>

				<hr />
				<footer class="page-footer">
					

<!--
<div class="author-image">
	<img src="https://wimvanderbauwhede.github.io/images/" alt="Wim Vanderbauwhede">
</div>
-->
<!-- ./author-image -->
<div class="author-content">
	<h3 class="author-name" >Written by <a href="http://www.dcs.gla.ac.uk/~wim" itemprop="author">Wim Vanderbauwhede</a></h3>
	<p class="author-bio"></p>
</div><!-- ./author-content -->

                    <div class="inline-btn">
    <a href="https://wimvanderbauwhede.github.io/atom.xml"><i class="fa fa-rss"></i></a>
</div><!-- /.follow-us -->

					
					<div class="page-meta">
	<p>Updated <time datetime="2022-10-15T00:00:00Z" itemprop="dateModified">October 15, 2022</time>
</div><!-- /.page-meta -->
				</footer><!-- /.footer -->
				<aside>
					
				</aside>
			</div><!-- /.content -->
		</div><!-- /.inner-wrap -->
		
	</article><!-- ./wrap -->
</div><!-- /#main -->


      <footer role="contentinfo" id="site-footer">
	<nav role="navigation" class="menu bottom-menu">
		<ul class="menu-item">
		
      
			<li><a href="https://wimvanderbauwhede.github.io/" >Wim Vanderbauwhede</a></li>
		
      
			<li><a href="https://wimvanderbauwhede.github.io/about/" >About</a></li>
		
		</ul>
	</nav><!-- /.bottom-menu -->
	<p class="copyright">&#169; 2024 <a href="https://wimvanderbauwhede.github.io">Wim Vanderbauwhede</a> <a rel="me" href="https://scholar.social/@wim_v12e">&nbsp;</a><br> <a href="http://jekyllrb.com">Jekyll</a> theme <a href="http://mmistakes.github.io/skinny-bones-jekyll/">Skinny Bones</a></p>

<!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=10807901;
var sc_invisible=1;
var sc_security="7dfdbc2d";
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
document.write("<sc"+"ript type='text/javascript' src='" +
scJsHost+
"statcounter.com/counter/counter.js'></"+"script>");
</script>
<noscript><div class="statcounter"><a title="web stats"
href="http://statcounter.com/" target="_blank"><img
class="statcounter"
src="http://c.statcounter.com/10807901/0/7dfdbc2d/1/"
alt="web stats"></a></div></noscript>
<!-- End of StatCounter Code for Default Guide -->

</footer>

    </div>

    <!-- <script src="https://wimvanderbauwhede.github.io/js/vendor/jquery-1.9.1.min.js"></script> -->
    <!-- <script src="https://wimvanderbauwhede.github.io/js/main.js"></script> -->

    

  </body>

</html>
